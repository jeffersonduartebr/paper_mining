{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LO7ZYzeden9c"
      },
      "outputs": [],
      "source": [
        "# Restart the session afther this cell to avoid Google Colab errors\n",
        "!pip install --upgrade --force-reinstall numpy==1.26.4 pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZF29icAhigEy"
      },
      "outputs": [],
      "source": [
        "!pip install pybibx\n",
        "!pip install tabulate tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGlz58a_iQhX"
      },
      "outputs": [],
      "source": [
        "# Dowload .bib file\n",
        "#!wget https://github.com/Valdecy/pyBibX/raw/main/assets/bibs/scopus.bib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUDAb0D_aV53"
      },
      "outputs": [],
      "source": [
        "# Required Libraries\n",
        "import textwrap\n",
        "import pandas as pd\n",
        "import bibtexparser\n",
        "from bibtexparser.bwriter import BibTexWriter\n",
        "from bibtexparser.bibdatabase import BibDatabase\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from functools import partial\n",
        "import pandas as pd\n",
        "import ollama\n",
        "\n",
        "from pybibx.base import pbx_probe\n",
        "from tabulate import tabulate\n",
        "from utils import preprocess_text, is_non_english, published_within_last_n_years, classify_abstract, log, load_and_filter_bases\n",
        "from batch import process_batch_with_retry, call_local_llm\n",
        "from inclusion import apply_inclusion_filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U94aI4NIjY-k"
      },
      "outputs": [],
      "source": [
        "# Load .bib\n",
        "# Arguments: file_bib = 'filename.bib'; db = 'scopus', 'wos', 'pubmed'; del_duplicated = True, False\n",
        "file_name = 'dados/scopus.bib'\n",
        "database  = 'scopus'\n",
        "bibfile   = pbx_probe(file_bib = file_name, db = database, del_duplicated = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(bibfile.data.document_type.value_counts())\n",
        "filtro = ['Article','Conference paper']\n",
        "bibfile.data = bibfile.data[bibfile.data['document_type'].isin(filtro)]\n",
        "print(bibfile.data.document_type.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_name_acm = 'dados/acm.bib'\n",
        "database_acm  = 'acm'\n",
        "bibfile_acm   = pbx_probe(file_bib = file_name_acm, db = database_acm, del_duplicated = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bibfile.merge_database(file_bib=file_name_acm, db=database_acm, del_duplicated=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bibfile.data['year'] = bibfile.data['year'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bibfile.data = bibfile.data[bibfile.data['year'] > 2019]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bja7UImUpuK"
      },
      "outputs": [],
      "source": [
        "# Health Analysis\n",
        "health = bibfile.health_bib()\n",
        "\n",
        "# Check Health\n",
        "health"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDwUW-yofYlI"
      },
      "outputs": [],
      "source": [
        "print(bibfile.data['abstract'].head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(bibfile.data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjFFdFz3gjX4"
      },
      "outputs": [],
      "source": [
        "!pip install pybtex\n",
        "!pip install bibtexparser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === CONFIGURAÇÕES GLOBAIS ===\n",
        "MAX_REQUESTS_PER_MINUTE = 300\n",
        "SECONDS_BETWEEN_REQUESTS = 60 / MAX_REQUESTS_PER_MINUTE\n",
        "BATCH_SIZE = 1\n",
        "WORKERS = min(8, cpu_count())\n",
        "MODELS = [\"llama3:8b\", \"gemma3:27b-it-qat\", \"phi4\"]\n",
        "TEMPERATURE = 0\n",
        "\n",
        "QUERY = (\n",
        "    #\"Does this abstract discuss artificial intelligence in feedback for learning management systems or online learning environment on education?\"\n",
        "    \"Analyze the following scientific article abstract and determine whether it \"\n",
        "     \"addresses the use of artificial intelligence to provide feedback in virtual learning environments.\\n\"\n",
        "     \"Consider aspects such as: the application of AI techniques, automated feedback systems, \"\n",
        "     \"digital educational platforms, and online learning. Respond only with ‘yes’ if the article is related, \"\n",
        "     \"or ‘no’ if it is not.\\n\\n\"\n",
        ")\n",
        "\n",
        "def chunk_dataframe(df, batch_size: int):\n",
        "    for i in range(0, len(df), batch_size):\n",
        "        yield df.iloc[i : i + batch_size], i\n",
        "\n",
        "\n",
        "def process_args_wrapper(args, query, model, temperature, seconds_between_requests, log_path):\n",
        "    return process_batch_with_retry(*args, query=query, model=model,\n",
        "                                    temperature=temperature,\n",
        "                                    seconds_between_requests=seconds_between_requests,\n",
        "                                    log_path=log_path)\n",
        "\n",
        "\n",
        "# === PIPELINE PARA UM MODELO ===\n",
        "def analyze_abstracts_parallel(\n",
        "    df: pd.DataFrame,\n",
        "    query: str,\n",
        "    model: str,\n",
        "    batch_size: int,\n",
        "    workers: int,\n",
        "    result_csv_path: str,\n",
        "    log_path: str,\n",
        "    temperature: float,\n",
        "    seconds_between_requests: float,\n",
        ") -> pd.DataFrame:\n",
        "    if os.path.exists(result_csv_path):\n",
        "        acumulado = pd.read_csv(result_csv_path)\n",
        "        start = len(acumulado)\n",
        "        log(f\"[{model}] Retomando do índice {start}\", log_path)\n",
        "    else:\n",
        "        acumulado = pd.DataFrame()\n",
        "        start = 0\n",
        "\n",
        "    to_process = df.iloc[start:].reset_index(drop=True)\n",
        "    batches = [\n",
        "        (batch, idx + start)\n",
        "        for batch, idx in chunk_dataframe(to_process, batch_size)\n",
        "    ]\n",
        "\n",
        "    log(f\"[{model}] Iniciando {len(batches)} lotes com {workers} workers\", log_path)\n",
        "\n",
        "    with Pool(processes=workers) as pool:\n",
        "        processor = partial(\n",
        "            process_args_wrapper,\n",
        "            query=query,\n",
        "            model=model,\n",
        "            temperature=temperature,\n",
        "            seconds_between_requests=seconds_between_requests,\n",
        "            log_path=log_path\n",
        "        )\n",
        "        for outcome in pool.imap_unordered(processor, batches):\n",
        "            if outcome:\n",
        "                df_part = pd.DataFrame(outcome)\n",
        "                acumulado = pd.concat([acumulado, df_part], ignore_index=True)\n",
        "                acumulado.to_csv(result_csv_path, index=False)\n",
        "\n",
        "    log(f\"[{model}] Processamento completo.\", log_path)\n",
        "    return acumulado\n",
        "\n",
        "\n",
        "# === RUN_ALL_MODELS MODIFICADA ===\n",
        "def run_all_models(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    #\n",
        "    #Executa o pipeline para todos os modelos em MODELS e retorna um DataFrame combinado\n",
        "    #contendo todas as colunas relevant_<model>.\n",
        "    #\n",
        "    combined = df.copy()\n",
        "\n",
        "    for model in MODELS:\n",
        "        model_name = model.split(\":\")[0]\n",
        "        result_path = f\"temp_files/resultados_parciais_{model_name}.csv\"\n",
        "        log_path = f\"temp_files/log_execucao_{model_name}.txt\"\n",
        "\n",
        "                # ajusta workers para alguns modelos (exemplo)\n",
        "        extra = 0\n",
        "        if model in (\"gemma3:27b-it-qat\",\"phi4-mini\"): extra = 4\n",
        "        workers = WORKERS + extra\n",
        "\n",
        "        resultados = analyze_abstracts_parallel(\n",
        "            df=combined,\n",
        "            query=QUERY,\n",
        "            model=model,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            workers=workers,\n",
        "            result_csv_path=result_path,\n",
        "            log_path=log_path,\n",
        "            temperature=TEMPERATURE,\n",
        "            seconds_between_requests=SECONDS_BETWEEN_REQUESTS\n",
        "        )\n",
        "\n",
        "        col = f\"relevant_{model_name}\"\n",
        "        combined = combined.merge(\n",
        "            resultados[[col]],\n",
        "            left_index=True, right_index=True\n",
        "        )\n",
        "\n",
        "    return combined\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "dados = bibfile.data\n",
        "df_ieee = load_and_filter_bases(\"dados\")\n",
        "colunas_desejadas_ieee = ['Document Title', 'Abstract', 'Author Affiliations', 'Authors', 'DOI', 'ISBNs',\n",
        "                             'ISSN', 'Publication Title', 'Publication Year']\n",
        "df_ieee = df_ieee[colunas_desejadas_ieee].copy()\n",
        "#print(df_ieee.columns)\n",
        "colunas_desejadas_scopus = ['title', 'abstract', 'journal', \n",
        "                            'affiliation', 'author', 'doi', 'isbn',\n",
        "                             'issn', 'year']\n",
        "\n",
        "df_scopus = dados[colunas_desejadas_scopus].copy()\n",
        "df_scopus = df_scopus.rename(columns={\n",
        "    'title': 'Document Title',\n",
        "    'abstract': 'Abstract',\n",
        "    'abbrev_source_title': 'Publication Title',\n",
        "    'affiliation': 'Author Affiliations',\n",
        "    'author': 'Authors',\n",
        "    'doi': 'DOI',\n",
        "    'isbn': 'ISBNs',\n",
        "    'issn': 'ISSN',\n",
        "    'journal': 'Publication Title',\n",
        "    'references': 'References',\n",
        "    'url': 'URL',\n",
        "    'year': 'Publication Year'\n",
        "})\n",
        "\n",
        "\n",
        "print(df_ieee.shape, '\\t', df_scopus.shape)\n",
        "dados = pd.concat([df_ieee, df_scopus], ignore_index=True)\n",
        "print('Antes da remoção de duplicados: ', dados.shape)\n",
        "dados.columns = dados.columns.str.lower()\n",
        "dados = dados.dropna(subset=['abstract'])\n",
        "dados = dados.drop_duplicates(subset=['abstract'])\n",
        "dados = dados.reset_index(drop=True)\n",
        "print('Após remoção de duplicados: ', dados.shape)\n",
        "\n",
        "resultados = run_all_models(dados)\n",
        "\n",
        "# Salvar CSV final (opcional)\n",
        "resultados.to_csv(\"temp_files/resultados_preliminares.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT68x1YipfZg"
      },
      "outputs": [],
      "source": [
        "print(resultados.columns)\n",
        "# Exibir os resultados\n",
        "for model in MODELS:\n",
        "    model_name = model.split(\":\")[0]\n",
        "    print(f\"\\nResultados para o modelo {model_name}:\")\n",
        "    print(resultados[f'relevant_{model_name}'].value_counts())\n",
        "#dados_filtered = resultados[resultados['relevant'] != 'False']\n",
        "#dados_filtered.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Avaliação da diferença entre os modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_committee(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Adiciona ao DataFrame uma coluna 'relevant' que será 'true' se a\n",
        "    maioria (≥3) das colunas ['a','b','c','d','e'] for 'true', caso\n",
        "    contrário 'false'.\n",
        "\n",
        "    Parâmetros\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame contendo as colunas 'a','b','c','d' e 'e', com valores\n",
        "        'true' ou 'false' (strings).\n",
        "\n",
        "    Retorna\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        O mesmo DataFrame, com a coluna 'relevant' adicionada.\n",
        "    \"\"\"\n",
        "    cols = ['relevant_llama3', 'relevant_gemma3', 'relevant_phi4']\n",
        "    # Verifica se as colunas existem no DataFrame\n",
        "    for col in cols:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"Coluna {col} não encontrada no DataFrame.\")\n",
        "    # Conta quantos 'true' por linha\n",
        "    true_counts = df[cols].eq(True).sum(axis=1)\n",
        "    # Define 'relevant' = 'true' se true_counts >= 3, senão 'false'\n",
        "    df['relevant'] = (true_counts >= 2).map({True: True, False: False})\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados_com_relevancia = apply_committee(resultados)\n",
        "resultados_com_relevancia.to_csv(\"temp_files/resultados_finais_com_relevancia.csv\", index=False)\n",
        "print(resultados_com_relevancia['relevant'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(resultados_com_relevancia['relevant'].value_counts())\n",
        "print(resultados_com_relevancia[resultados_com_relevancia['relevant'] == True])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Critrérios de exclusão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Livro\n",
        "2. Artigos resumidos\n",
        "3. Revisões de literatura\n",
        "4. Relatórios técnicos\n",
        "5. Escrito em língua estrangeira que não seja o inglês\n",
        "6. Simulou cenários\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# Critérios de Exclusão\n",
        "# ----------------------------\n",
        "criterios_exclusao: dict[str, str] = {\n",
        "\"QE1\": \"Is it a Book?\",\n",
        "\"QE2\": \"Is it a Summarized articles\",\n",
        "\"QE3\": \"Is it a Literature reviews\",\n",
        "\"QE4\": \"Is it aTechnical reports\",\n",
        "\"QE5\": \"Was it written in a language other than English\",\n",
        "\"QE6\": \"Is it a Simulated scenarios\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from langdetect import detect\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Configura o zero-shot para QE1, QE2, QE3, QE4 e QE6\n",
        "# ----------------------------\n",
        "classifier = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model=\"facebook/bart-large-mnli\",\n",
        "    device=0  # use -1 para CPU\n",
        ")\n",
        "\n",
        "# Labels sem QE5\n",
        "labels = [criterios_exclusao[k] for k in criterios_exclusao if k != \"QE5\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exclusion_log = \"temp_files/log_exclusao.txt\"\n",
        "resultados_com_relevancia_apenas_True = resultados_com_relevancia[resultados_com_relevancia['relevant'] == True]\n",
        "resultados_com_relevancia_apenas_True = resultados_com_relevancia_apenas_True.reset_index(drop=True)\n",
        "\n",
        "\n",
        "resultados_com_relevancia_apenas_True[\"abstract_pp\"] = resultados_com_relevancia_apenas_True[\"abstract\"].apply(preprocess_text)\n",
        "\n",
        "resultados_com_relevancia_apenas_True[\"exclude\"] = resultados_com_relevancia_apenas_True[\"abstract_pp\"].apply(is_non_english)\n",
        "\n",
        "# 3) Aplica zero-shot apenas onde ainda não foi marcado como exclude\n",
        "for idx, row in resultados_com_relevancia_apenas_True.iterrows():\n",
        "    if not row[\"exclude\"]:\n",
        "        preds = classify_abstract(criterios_exclusao,classifier, labels ,row[\"abstract_pp\"])\n",
        "        if any(preds.values()):\n",
        "            resultados_com_relevancia_apenas_True.at[idx, \"exclude\"] = True\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Exibe resultado final\n",
        "# ----------------------------\n",
        "print(resultados_com_relevancia_apenas_True[[\"authors\", \"exclude\"]])\n",
        "\n",
        "resultados_com_relevancia_apenas_True.to_csv(\"temp_files/resultados_criterios_exclusao.csv\", index=False)\n",
        "print(\"Pipeline completa! Resultados em temp_files/resultados_criterios_exclusao.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(resultados_com_relevancia_apenas_True[resultados_com_relevancia_apenas_True['exclude'] == False].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Critérios de inclusão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Forneceu feedback automatizados para os estudantes\n",
        "2. Artigos primários\n",
        "3. Publicado nos últimos cinco anos\n",
        "4. Estudos envolvendo aprendizes em qualquer nível educacional (fundamental, médio, superior, formação corporativa) que utilizem um AVA\n",
        "5. Implementações de inteligência artificial (machine learning, NLP, agentes conversacionais, sistemas especialistas, etc.) voltadas à geração de feedback automatizado\n",
        "6. Ambientes virtuais de aprendizagem (Moodle, Canvas, Blackboard, Google Classroom, Open edX, entre outros)\n",
        "7. Trabalhos que relatem pelo menos um dos seguintes resultados:\n",
        "\n",
        "    7.1. Qualidade / utilidade do feedback\n",
        "\n",
        "    7.2. Impacto no desempenho acadêmico ou engajamento\n",
        "\n",
        "    7.3. Satisfação dos estudantes ou docentes\n",
        "    \n",
        "    7.4. Métricas de eficiência do sistema (tempo, custo, escalabilidade).\n",
        "\n",
        "8. Estudos empíricos (experimentos controlados, quase‑experimentos, estudos de caso, design‑based research) e relatos de desenvolvimento avaliados (artigos de conference/journal com validação)\n",
        "9. Publicações revisadas por pares: artigos de periódicos, capítulos de livro, anais de conferências.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inclusos = resultados_com_relevancia_apenas_True[resultados_com_relevancia_apenas_True['exclude'] == False]\n",
        "df_inclusos = df_inclusos.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_inclusos.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# ----------------------------\n",
        "# Critérios de Inclusão\n",
        "# ----------------------------\n",
        "criterios_inclusao: dict[int, str] = {\n",
        "    1: \"Provided automated feedback to students\",\n",
        "    2: \"Primary research article\",\n",
        "    3: \"Published in the last fifteen years\",\n",
        "    4: \"Involves learners at any educational level using a virtual learning environment\",\n",
        "    5: \"AI implementations aimed at automated feedback generation\",\n",
        "    6: \"Virtual learning environments like Moodle, Canvas, Blackboard, Google Classroom, Open edX\",\n",
        "    7: \"Reports outcomes such as quality or usefulness of feedback, academic performance or engagement impact, satisfaction, or system efficiency metrics\",\n",
        "    8: \"Empirical study (controlled experiment, quasi-experiment, case study, design-based research)\",\n",
        "    9: \"Peer-reviewed publication (journal article, conference paper, thesis, dissertation)\"\n",
        "}\n",
        "\n",
        "# Sublabels para o critério 7 (pelo menos um deve ser atendido)\n",
        "sublabels_7 = [\n",
        "    \"Feedback quality or usefulness\",\n",
        "    \"Impact on academic performance or engagement\",\n",
        "    \"Student or teacher satisfaction\",\n",
        "    \"System efficiency metrics like time, cost, scalability\"\n",
        "]\n",
        "\n",
        "# ----------------------------\n",
        "# Configura zero-shot classifier\n",
        "# ----------------------------\n",
        "classifier = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model=\"facebook/bart-large-mnli\",\n",
        "    device=0  # use -1 para CPU\n",
        ")\n",
        "threshold = 0.7\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0)\n",
        "df_inclusos = apply_inclusion_filter(df_inclusos, classifier, criterios_inclusao, sublabels_7)\n",
        "print(df_inclusos[[\"authors\", \"include\"]].head(5))\n",
        "\n",
        "# Exibe o resultado\n",
        "print(df_inclusos[[\"authors\", \"publication year\", \"document title\", \"include\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_inclusos[[\"authors\", \"document title\", \"doi\", \"include\"]].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inclusos.drop(columns=[\"abstract_pp\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inclusos.to_csv(\"temp_files/resultados_pos_processamento.csv\", index=False, sep=\",\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
